{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents:\n",
    " * [Part 1](#Introduction-to-Machine-Learning---Part-1)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning - Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import importlib\n",
    "import mlintro_min as mli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Simple regression (OLS) model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Range of cannon angle psi to investigate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "psi_min=20\n",
    "psi_max=60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Read pre-generated source of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ref_df = pd.read_csv('datasets/offline/refdata_100K.csv')\n",
    "# Get a very small subset of inter-spread data for plotting\n",
    "ref_df_light = mli.get_ref_light(ref_df, psi_min=psi_min, psi_max=psi_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Generate a single dataset of 50 observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "ds = mli.get_datasets(ref_df, n_datasets=1, sample_size=50, \n",
    "                      psi_min=psi_min, psi_max=psi_max)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##### Explore dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We are only interested in experimental measures of angle and range, `exp_angle` and `exp_range` respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Exercise \n",
    "Plot the (experimentally) measured range `exp_range` as a function of the (experimentally) measured angle `exp_angle`, once with matplotlib `plt.scatter()` function, and once with seaborn `sns.scatterplot()` function.  \n",
    "\n",
    "* HINT 1: look at the functions help to know which function arguments to use\n",
    "* HINT 2: you can call these functions in two ways:\n",
    "  * either extract the columns you want to plot and give them as parameters `x` and `y`, OR\n",
    "  * just provide the column names as arguments for `x` and `y`,  and provide the dataframe name as argument to the parameter `data`. This approach is preferred.\n",
    "* HINT 3: if using the first method mentioned in HINT 2, remember you can extract a column from a dataframe either as a single column `pandas` object called a `Series` with `[ ]`, or as a `DataFrame` object with `[[ ]]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "#Write plot commands here\n",
    "plt.ylim([50, 80]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Part 1: model selection with train / test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We will compare three models of different complexity (different number of parameters):\n",
    "   * Standard linear model (2 parameters: $\\beta_0$, $\\beta_\\psi$)\n",
    "   * Linear model with the feature squared (3 parameters: $\\beta_0$, $\\beta_\\psi$, $\\beta_{\\psi^2}$)\n",
    "   * Linear model with up to $5^{th}$ power of feature (6 parameters: $\\beta_0$, $\\beta_\\psi$, $\\beta_{\\psi^2}$, $\\beta_{\\psi^3}$, $\\beta_{\\psi^4}$, $\\beta_{\\psi^5}$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's divide our dataset into training and test set !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "X = ds[['exp_angle']]\n",
    "y = ds[['exp_range']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "print(f\"Number of observations: {len(X_train)} for training and {len(X_test)} for testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# We simply used tuple unpacking\n",
    "a, b, c = 1, 13, 42\n",
    "print(f'a={a}, b={b}, c={c}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T20:06:42.259063Z",
     "start_time": "2020-06-14T20:06:42.249379Z"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Linear (OLS) model with single feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "##### Let's train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Create new estimator object (each model is an object in `sklearn`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "lm = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "lm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "lm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "lm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(f'beta_psi: {lm.coef_}, beta_0: {lm.intercept_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##### Predict, and compute performance scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "lm.predict([[30], [45], [60]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The training score can provide an idea of best possible performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# We score the predictions made on the same data we trained on\n",
    "y_pred = lm.predict(X_train)\n",
    "\n",
    "R2_train = r2_score(y_train, y_pred)\n",
    "MSE_train = mean_squared_error(y_train, y_pred)\n",
    "print(f'lm training performance is R2: {R2_train:0.2f} and MSE: {MSE_train:0.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`R2` can be obtained directly from the model / estimator object as it is the default for `LinearRegression`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "lm.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's save all our models scores to compare models later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "train_test_results = []\n",
    "train_test_results.append({'model': 'lm', 'stage': 'train', \n",
    "                           'scorer': 'r2', 'val': R2_train})\n",
    "train_test_results.append({'model': 'lm', 'stage': 'train', \n",
    "                           'scorer': 'MSE', 'val': -MSE_train})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##### Let's test on unseen data and get testing score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "See possible scores: https://scikit-learn.org/stable/modules/model_evaluation.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The testing score can provide an idea of performance for unseen data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Exercise\n",
    "Let's use the fitted model to see its performance on unseen data. As above, use the `lm.predict()`, `r2_score()` and `mean_squared_error()` functions, but this time to get the scores on the unseen data `X_test`. The predictions of `X_test` have to be compared with the ground truth data `y_test`.\n",
    "* HINT 1: copy the relevant code, and replace the training data with the testing data where required\n",
    "* HINT 2: you should find as performance R2: 0.26 and MSE: 33.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# We score the predictions made on unseen data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Again let's save our scores for comparison later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "train_test_results.append({'model': 'lm', 'stage': 'test', \n",
    "                           'scorer': 'r2', 'val': R2_test})\n",
    "train_test_results.append({'model': 'lm', 'stage': 'test', \n",
    "                           'scorer': 'MSE', 'val': -MSE_test})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Polynomial degree 2 model (polynomial use feature powers as additional features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "##### Train and get training score of degree 2 polynomial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The polynomial terms are created and then added to a standard `LinearRegression`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "poly_transformer = PolynomialFeatures(degree=2)\n",
    "lm_deg2 = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A polynomial model is fitted by first transforming the features and then training a `LinearRegression` on the transformed features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "X_train_deg2 = poly_transformer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "X_train_deg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "lm_deg2.fit(X_train_deg2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "lm_deg2.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's compute training score  \n",
    "**Warning**: `LinearRegression` needs to be applied to the *transformed* (polynomial) features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = lm_deg2.predict(X_train_deg2)\n",
    "\n",
    "R2_train = r2_score(y_train, y_pred)\n",
    "MSE_train = mean_squared_error(y_train, y_pred)\n",
    "print(f'poly deg2 training performance is R2: {R2_train:0.2f} and MSE: {MSE_train:0.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "train_test_results.append({'model': 'lm_deg2', 'stage': 'train', \n",
    "                           'scorer': 'r2', 'val': R2_train})\n",
    "train_test_results.append({'model': 'lm_deg2', 'stage': 'train', \n",
    "                           'scorer': 'MSE', 'val': -MSE_train})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##### Let's test on unseen data and get testing score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Again, should not forget to transform the test data to get polynomial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "X_test_deg2 = poly_transformer.fit_transform(X_test) \n",
    "\n",
    "y_pred = lm_deg2.predict(X_test_deg2)\n",
    "\n",
    "R2_test = r2_score(y_test, y_pred)\n",
    "MSE_test = mean_squared_error(y_test, y_pred)\n",
    "print(f'poly deg2 testing performance is R2: {R2_test:0.2f} and MSE: {MSE_test:0.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "train_test_results.append({'model': 'lm_deg2', 'stage': 'test', \n",
    "                           'scorer': 'r2', 'val': R2_test})\n",
    "train_test_results.append({'model': 'lm_deg2', 'stage': 'test', \n",
    "                           'scorer': 'MSE', 'val': -MSE_test})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Polynomial degree 5 model, introducing pipeline object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "It is common to use preprocessing steps such as features transformation. To avoid repeating these processing steps (e.g. when testing the model on new data) the `Pipeline` object is very useful. It builds a workflow which can be called with a single command. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##### Train and get training score of degree 5 polynomial with *pipeline*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The creation of the polynomial terms are embed in the `Pipeline` object which represents our new estimator (i.e. the one to use with `fit`, `predict`, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "lm_deg5 = Pipeline([('poly_transformer', PolynomialFeatures(degree=5)),\n",
    "                    ('lm', LinearRegression())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Exercise\n",
    "Train and test your \"degree 5\"-polynomial model, and get both the training and testing scores (R2 and MSE).  \n",
    "1. Fit  your pipeline model on `X_train` and `y_train` with the `lm_deg5.fit()` method (you only need to call this method because the pipeline object will take care of calling the required `transform` and `fit` methods of all the pipeline objects)\n",
    "2. Examine your fitted linear model coefficients. Because your model is a pipeline object including `poly_transformer` and `lm`, you have to look at the specific `lm` object accessible with `lm_deg5['lm']` \n",
    "3. Compute the R2 and MSE training score by comparing predictions on `X_train` (you can name them `y_pred`) with the ground truth `y_train`, and save them in the variables `R2_train` and `MSE_train` respectively\n",
    "4. Run the cell further down below to append the training scores to the `train_test_results` variable\n",
    "5. Using the fitted model on step 1, now compute the R2 and MSE testing scores by comparing predictions on `X_test` with `y_test`, and save them in the variables `R2_test` and `MSE_test` respectively\n",
    "6. Run the cell further down below to append the test scores to the `train_test_results` variable\n",
    "\n",
    "HINT: Copy previous code and adapt it as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# For Step 4\n",
    "train_test_results.append({'model': 'lm_deg5', 'stage': 'train', \n",
    "                           'scorer': 'r2', 'val': R2_train})\n",
    "train_test_results.append({'model': 'lm_deg5', 'stage': 'train', \n",
    "                           'scorer': 'MSE', 'val': -MSE_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# For Step 6\n",
    "train_test_results.append({'model': 'lm_deg5', 'stage': 'test', \n",
    "                           'scorer': 'r2', 'val': R2_test})\n",
    "train_test_results.append({'model': 'lm_deg5', 'stage': 'test', \n",
    "                           'scorer': 'MSE', 'val': -MSE_test})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##### Plot all the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# The list of dictionaries is transformed into a Pandas dataframe\n",
    "train_test_results_df = pd.DataFrame(train_test_results)\n",
    "# We extract the r2 score results\n",
    "r2_results = train_test_results_df.loc[train_test_results_df['scorer'] == 'r2']\n",
    "# We extract the MSE score results\n",
    "MSE_results = train_test_results_df.loc[train_test_results_df['scorer'] == 'MSE']\n",
    "# We call the seaborn `catplot` function which can plot 4 level of informations:\n",
    "# x [model: lm, lm_deg2, ...], y [score value], colored by `hue` [training or testing score], \n",
    "# and producing separate plots for each `col` [score metric: r2 or MSE]\n",
    "with sns.plotting_context(\"notebook\", font_scale=1.2):\n",
    "    g = sns.catplot(x=\"model\", y=\"val\", hue=\"stage\", col=\"scorer\", \n",
    "                    data=train_test_results_df, kind=\"bar\", sharey=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For many other regression models implemented in sklearn, cf https://scikit-learn.org/stable/supervised_learning.html#supervised-learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Part 2: Model selection with cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "https://scikit-learn.org/stable/modules/cross_validation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "KFold?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's see what K fold is actually doing on a 10-observation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center",
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "X_example = pd.DataFrame({'obs': \n",
    "                          np.random.randint(0, 1000, 10)})\n",
    "X_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "for (ix_train, ix_test) in kf.split(X_example):\n",
    "    print(\"train ix:\", ix_train, \"testix:\", ix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "kfs = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for (ix_train, ix_test) in kfs.split(X_example):\n",
    "    print(\"train ix:\", ix_train, \"test ix:\", ix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "print(f\"Size X: {len(X)}, with X train: {len(X_train)} and X test: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "ml_models = {'lm': LinearRegression(),\n",
    "             'lm_deg2': Pipeline([('poly_transformer', PolynomialFeatures(degree=2)),\n",
    "                                  ('lm', LinearRegression())]),\n",
    "             'lm_deg5': Pipeline([('poly_transformer', PolynomialFeatures(degree=5)),\n",
    "                                  ('lm', LinearRegression())])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "kf_results = []\n",
    "\n",
    "kfs = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "for i_f, (ix_train, ix_test) in enumerate(kfs.split(X_train)):\n",
    "    # Loop over models\n",
    "    for mod_name, mod in ml_models.items():\n",
    "        # Define training and testing folds\n",
    "        X_training_folds = X_train.iloc[ix_train]\n",
    "        y_training_folds = y_train.iloc[ix_train]\n",
    "        X_test_fold = X_train.iloc[ix_test]\n",
    "        y_test_fold = y_train.iloc[ix_test]\n",
    "        # Fit the model on the training folds\n",
    "        mod.fit(X_training_folds, y_training_folds)\n",
    "        # Test on both the training and testing folds to check for over-/under-fitting\n",
    "        y_pred_train = mod.predict(X_training_folds)\n",
    "        y_pred_test = mod.predict(X_test_fold)\n",
    "        # R2\n",
    "        kf_results.append({'model': mod_name, 'fold': i_f, 'stage': 'train', 'scorer': 'r2', \n",
    "                           'val': r2_score(y_training_folds, y_pred_train)})\n",
    "        kf_results.append({'model': mod_name, 'fold': i_f, 'stage': 'test', 'scorer': 'r2', \n",
    "                           'val': r2_score(y_test_fold, y_pred_test)})\n",
    "        # MSE\n",
    "        kf_results.append({'model': mod_name, 'fold': i_f, 'stage': 'train', 'scorer': 'MSE', \n",
    "                           'val': -mean_squared_error(y_training_folds, y_pred_train)})\n",
    "        kf_results.append({'model': mod_name, 'fold': i_f, 'stage': 'test', 'scorer': 'MSE', \n",
    "                           'val': -mean_squared_error(y_test_fold, y_pred_test)})\n",
    "kf_results_df = pd.DataFrame(kf_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "for mod_name in ml_models.keys():\n",
    "    kf_df = kf_results_df.loc[kf_results_df['model'] == mod_name]\n",
    "    with sns.plotting_context(\"notebook\", font_scale=1.2):\n",
    "        g = sns.catplot(x=\"fold\", y=\"val\", hue=\"stage\", col=\"scorer\", data=kf_df, \n",
    "                        kind=\"bar\", sharey=False, height=3, aspect=1.5)\n",
    "        g.axes[0,0].set_ylim(-0.2,1)\n",
    "        #g.axes[0,1].set_ylim(0, 45)\n",
    "        g.fig.suptitle(mod_name, y=1.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "with sns.plotting_context(\"notebook\", font_scale=1.2):\n",
    "    g = sns.catplot(x=\"model\", y=\"val\", hue=\"stage\", col=\"scorer\", data=kf_results_df, \n",
    "                    kind=\"box\", sharey=False, height=3, aspect=1.5)\n",
    "    g.axes[0, 0].set_ylim(-0.2, 1)\n",
    "    g.axes[0, 1].set_ylim(-50, 0)\n",
    "    g.fig.suptitle(\"Score accross fold across models\", y=1.05)\n",
    "    g = sns.catplot(x=\"model\", y=\"val\", hue=\"stage\", col=\"scorer\", data=kf_results_df, \n",
    "                    kind=\"box\", sharey=False, height=3, aspect=1.5)\n",
    "    g.axes[0, 0].set_ylim(0.45, 1)\n",
    "    g.axes[0, 1].set_ylim(-18, 0)\n",
    "    g.fig.suptitle(\"Close up on polynomial models\", y=1.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### `sklearn` helps to automate common operations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "cross_val_score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "mse_scorer = make_scorer(mean_squared_error, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "ml_models = {'lm': LinearRegression(),\n",
    "             'lm_deg2': Pipeline([('poly_transformer', PolynomialFeatures(degree=2)),\n",
    "                                  ('lm', LinearRegression())]),\n",
    "             'lm_deg5': Pipeline([('poly_transformer', PolynomialFeatures(degree=5)),\n",
    "                                  ('lm', LinearRegression())])}\n",
    "# Get cv train AND test scores\n",
    "cv_test_scores = {}\n",
    "for mod_name in ml_models.keys():\n",
    "    cv_test_scores[mod_name] = cross_val_score(ml_models[mod_name], X_train, y_train, \n",
    "                                               cv=kfs, scoring=mse_scorer, n_jobs=-1)\n",
    "cv_test_scores_df = pd.DataFrame(cv_test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "cv_test_scores_df.boxplot()\n",
    "plt.title('Negative MSE for the three models tested (larger is better)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##### Want even more with even less code?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`cross_validate` returns train *and* test scores on *several* metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "cross_validate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "ml_models = {'lm': LinearRegression(),\n",
    "             'lm_deg2': Pipeline([('poly_transformer', PolynomialFeatures(degree=2)),\n",
    "                                  ('lm', LinearRegression())]),\n",
    "             'lm_deg5': Pipeline([('poly_transformer', PolynomialFeatures(degree=5)),\n",
    "                                  ('lm', LinearRegression())])}\n",
    "# Get cv train AND test scores\n",
    "cv_scores = {}\n",
    "for mod_name in ml_models.keys():\n",
    "    cv_scores[mod_name] = cross_validate(ml_models[mod_name], X_train, y_train, cv=kfs, \n",
    "                                         scoring=['r2', 'neg_mean_squared_error'], \n",
    "                                         return_train_score=True, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def crossval_to_df(cv_dict):\n",
    "    crossval_results = []\n",
    "    for model in cv_dict.keys():\n",
    "        for scorer in cv_dict[model].keys():\n",
    "            if scorer.startswith('train_'):\n",
    "                score = scorer.replace('train_', '')\n",
    "                for i_val, val in enumerate(cv_dict[model][scorer]):\n",
    "                    crossval_results.append({'model': model, 'fold': i_val, 'stage': 'train', \n",
    "                                             'scorer': score, 'val': val})\n",
    "            elif scorer.startswith('test_'):\n",
    "                score = scorer.replace('test_', '')\n",
    "                for i_val, val in enumerate(cv_dict[model][scorer]):\n",
    "                    crossval_results.append({'model': model, 'fold': i_val, 'stage': 'test', \n",
    "                                             'scorer': score, 'val': val})\n",
    "    return pd.DataFrame(crossval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1
    ],
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "crossval_df = crossval_to_df(cv_scores)\n",
    "for mod_name in crossval_df['model'].unique():\n",
    "    kf_df = crossval_df.loc[crossval_df['model'] == mod_name]\n",
    "    with sns.plotting_context(\"notebook\", font_scale=1.2):\n",
    "        g = sns.catplot(x=\"fold\", y=\"val\", hue=\"stage\", col=\"scorer\", data=crossval_df,\n",
    "                        kind=\"bar\", sharey=False, height=3, aspect=1.5, errorbar=None)\n",
    "        g.axes[0,0].set_ylim(-0.2,1)\n",
    "        g.axes[0,1].set_ylim(-45, 0)\n",
    "        g.fig.suptitle(mod_name, y=1.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ds310]",
   "language": "python",
   "name": "conda-env-ds310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
